{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Classification problem"
      ],
      "metadata": {
        "id": "LimGMO4XfLEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SQMEAcpK5A1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown --folder # add google drive path link to your classification_challenge folder\n",
        "\n",
        "train_x3 = train_img = np.loadtxt('classification_challenge/loaded_data/x_train.csv', delimiter=',', encoding='utf-8', dtype='uint8')\n",
        "valid_x3 = valid_img = np.loadtxt('classification_challenge/loaded_data/x_valid.csv', delimiter=',', encoding='utf-8', dtype='uint8')\n",
        "test_x3 = test_img = np.loadtxt('classification_challenge/loaded_data/x_test.csv', delimiter=',', encoding='utf-8', dtype='uint8')\n",
        "\n",
        "train_x1 = train_lab = np.loadtxt('classification_challenge/loaded_data/t_train.csv', delimiter=',', encoding='utf-8', dtype='uint8')\n",
        "valid_x1 = valid_lab = np.loadtxt('classification_challenge/loaded_data/t_valid.csv', delimiter=',', encoding='utf-8', dtype='uint8')\n",
        "test_x1 = test_lab = np.loadtxt('classification_challenge/loaded_data/t_test.csv', delimiter=',', encoding='utf-8', dtype='uint8')\n"
      ],
      "metadata": {
        "id": "uAJjbba5LJAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = train_x3.reshape(-1, 28, 28, 1)\n",
        "valid_img= valid_x3.reshape(-1, 28, 28, 1)\n",
        "test_img = test_x3.reshape(-1, 28, 28, 1)\n",
        "\n",
        "train_img = np.swapaxes(train_img, 1, 2)\n",
        "valid_img = np.swapaxes(valid_img, 1, 2)\n",
        "test_img = np.swapaxes(test_img, 1, 2)\n",
        "\n",
        "train_img.shape\n"
      ],
      "metadata": {
        "id": "FDfU_Ju6LJLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "train_img = train_img.astype(\"float32\") / 255\n",
        "test_img = test_img.astype(\"float32\") / 255\n",
        "\n",
        "print(\"train_img shape:\", train_img.shape)\n",
        "print(train_img.shape[0], \"train samples\")\n",
        "print(test_img.shape[0], \"test samples\")\n",
        "\n",
        "train_lab = keras.utils.to_categorical(train_lab, num_classes)\n",
        "test_lab = keras.utils.to_categorical(test_lab, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "vRe4WWKxLJVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(train_img, train_lab, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "score = model.evaluate(test_img, test_lab, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "metadata": {
        "id": "JCjatWY8LfAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.load('classification_challenge/loaded_data/x_eval.npy')\n",
        "sequences = sequences.astype('float32')/255\n",
        "\n",
        "sequences = np.swapaxes(sequences,0,3)\n",
        "sequences = np.swapaxes(sequences,2,3)\n",
        "sequences = np.swapaxes(sequences,1,2)\n",
        "\n",
        "predictions = np.argmax(model.predict(sequences), axis = 1)\n",
        "predictions\n",
        "np.savetxt(\"classifications.csv\", predictions, fmt=\"%d\", delimiter=\",\")\n"
      ],
      "metadata": {
        "id": "a_4oNCCcLfFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}